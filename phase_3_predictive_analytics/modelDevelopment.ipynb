{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2530cd2a",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8351ef",
   "metadata": {},
   "source": [
    "### Prepping data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "eacc6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.75.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.10.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow scikit-learn pandas matplotlib seaborn numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9b2ce5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "833be42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>825.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>976.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0  2004-01-04   0:00:00     1.6       1143.0     106.0       6.3   \n",
       "1  2004-01-04  22:00:00     2.0       1186.0     188.0       9.9   \n",
       "2  2004-01-04  21:00:00     2.5       1192.0     254.0      10.8   \n",
       "3  2004-01-04  20:00:00     4.9       1536.0     655.0      20.2   \n",
       "4  2004-01-04  19:00:00     5.5       1592.0     840.0      25.0   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0          825.0     96.0         986.0     86.0        1477.0        978.0   \n",
       "1          976.0    127.0         844.0    113.0        1570.0       1200.0   \n",
       "2         1007.0    154.0         827.0    124.0        1604.0       1223.0   \n",
       "3         1302.0    269.0         666.0    161.0        1922.0       1599.0   \n",
       "4         1429.0    267.0         624.0    164.0        2089.0       1644.0   \n",
       "\n",
       "      T    RH      AH year_month  \n",
       "0  12.0  61.6  0.8593    2004-01  \n",
       "1  15.8  48.0  0.8569    2004-01  \n",
       "2  16.8  44.0  0.8341    2004-01  \n",
       "3  18.3  40.9  0.8493    2004-01  \n",
       "4  20.8  36.7  0.8878    2004-01  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all the CSV files in the directory\n",
    "data_dir = '../data'\n",
    "all_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "df_list = [pd.read_csv(f) for f in all_files]\n",
    "data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Sort by datatimestamp\n",
    "data = data.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "509463c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                0\n",
       "Time                0\n",
       "CO(GT)           1283\n",
       "PT08.S1(CO)       385\n",
       "NMHC(GT)         6784\n",
       "C6H6(GT)          385\n",
       "PT08.S2(NMHC)     385\n",
       "NOx(GT)          1495\n",
       "PT08.S3(NOx)      385\n",
       "NO2(GT)          1499\n",
       "PT08.S4(NO2)      385\n",
       "PT08.S5(O3)       385\n",
       "T                 385\n",
       "RH                385\n",
       "AH                385\n",
       "year_month          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba128bf2",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "655a9d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>825.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>976.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  \\\n",
       "0     1.6       1143.0     106.0       6.3          825.0     96.0   \n",
       "1     2.0       1186.0     188.0       9.9          976.0    127.0   \n",
       "2     2.5       1192.0     254.0      10.8         1007.0    154.0   \n",
       "3     4.9       1536.0     655.0      20.2         1302.0    269.0   \n",
       "4     5.5       1592.0     840.0      25.0         1429.0    267.0   \n",
       "\n",
       "   PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  Year  \\\n",
       "0         986.0     86.0        1477.0        978.0  12.0  61.6  0.8593  2004   \n",
       "1         844.0    113.0        1570.0       1200.0  15.8  48.0  0.8569  2004   \n",
       "2         827.0    124.0        1604.0       1223.0  16.8  44.0  0.8341  2004   \n",
       "3         666.0    161.0        1922.0       1599.0  18.3  40.9  0.8493  2004   \n",
       "4         624.0    164.0        2089.0       1644.0  20.8  36.7  0.8878  2004   \n",
       "\n",
       "   Month  Day  DayOfWeek  IsWeekend  Hour  \n",
       "0      1    4          6          1     0  \n",
       "1      1    4          6          1    22  \n",
       "2      1    4          6          1    21  \n",
       "3      1    4          6          1    20  \n",
       "4      1    4          6          1    19  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Date related columns from 'Date' column\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
    "data['IsWeekend'] = data['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Convert time column to datetime\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S')\n",
    "data['Hour'] = data['Time'].dt.hour\n",
    "\n",
    "data = data.drop(columns=['Time', 'year_month', 'Date'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "825f1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Season column\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "data['Season'] = data['Month'].apply(get_season)\n",
    "\n",
    "# One-hot encoding for Season\n",
    "data = pd.get_dummies(data, columns=['Season'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a0c103e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for Year\n",
    "data = pd.get_dummies(data, columns=['Year'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7565c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical Encoding for hour\n",
    "data['Hour_sin'] = np.sin(2 * np.pi * data['Hour'] / 24)\n",
    "data['Hour_cos'] = np.cos(2 * np.pi * data['Hour'] / 24)\n",
    "data = data.drop(columns=['Hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "294135c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycilical Encoding for Month\n",
    "data['Month_sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
    "data['Month_cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
    "data = data.drop(columns=['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c026d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "688f41dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)',\n",
       "       'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)',\n",
       "       'T', 'RH', 'AH', 'Day', 'DayOfWeek', 'IsWeekend', 'Season_spring',\n",
       "       'Season_summer', 'Season_winter', 'Year_2005', 'Hour_sin', 'Hour_cos',\n",
       "       'Month_sin', 'Month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff804e3",
   "metadata": {},
   "source": [
    "### Baseline Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "54252daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT)</th>\n",
       "      <td>0.684330</td>\n",
       "      <td>1.141277</td>\n",
       "      <td>0.243215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <td>3.736177</td>\n",
       "      <td>33.390092</td>\n",
       "      <td>0.313139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <td>12.280400</td>\n",
       "      <td>3126.714984</td>\n",
       "      <td>0.324911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOx(GT)</th>\n",
       "      <td>78.551155</td>\n",
       "      <td>17431.584722</td>\n",
       "      <td>0.455097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2(GT)</th>\n",
       "      <td>21.128452</td>\n",
       "      <td>1030.288784</td>\n",
       "      <td>0.446477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MAE          RMSE        R2\n",
       "CO(GT)     0.684330      1.141277  0.243215\n",
       "C6H6(GT)   3.736177     33.390092  0.313139\n",
       "NMHC(GT)  12.280400   3126.714984  0.324911\n",
       "NOx(GT)   78.551155  17431.584722  0.455097\n",
       "NO2(GT)   21.128452   1030.288784  0.446477"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive pred using prev value\n",
    "targets = ['CO(GT)', 'C6H6(GT)', 'NMHC(GT)', 'NOx(GT)', 'NO2(GT)']  # add others as needed\n",
    "baseline_results = {}\n",
    "\n",
    "for target in targets:\n",
    "    y = data[target].fillna(method='ffill')  \n",
    "    y_pred = y.shift(1).iloc[1:]            \n",
    "    y_true = y.iloc[1:]\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    baseline_results[target] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "    \n",
    "baseline_results_df = pd.DataFrame(baseline_results).T\n",
    "baseline_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605fcd2",
   "metadata": {},
   "source": [
    "### Define Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6a63a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (CO)\n",
    "targetCO = data['CO(GT)']\n",
    "otherSensorsCO = ['PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresCO = data[['PT08.S1(CO)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsCO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3640d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NOx)\n",
    "targetNOx = data['NOx(GT)']\n",
    "otherSensorsNOx = ['PT08.S2(NMHC)', 'PT08.S1(CO)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresNOx = data[['PT08.S3(NOx)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNOx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f1e6c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NMHC)\n",
    "targetNMHC = data['NMHC(GT)']\n",
    "otherSensorsNMHC = ['PT08.S1(CO)', 'PT08.S3(NOx)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresNMHC = data[['PT08.S2(NMHC)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNMHC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "50df5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NO2)\n",
    "targetNO2 = data['NO2(GT)']\n",
    "otherSensorsNO2 = ['PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S5(O3)']\n",
    "featuresNO2 = data[['PT08.S4(NO2)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNO2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e8bc357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (C6H6)\n",
    "targetC6H6 = data['C6H6(GT)']\n",
    "otherSensorsC6H6 = ['PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)']\n",
    "featuresC6H6 = data[['PT08.S5(O3)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsC6H6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40c3b6",
   "metadata": {},
   "source": [
    "### Random Forest for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "46e89030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.6473\n",
      "Random Forest R2: 0.6632\n",
      "Random Forest MAE: 0.5388\n"
     ]
    }
   ],
   "source": [
    "# Random forest for CO prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresCO) * 0.8)\n",
    "X_train, X_test = featuresCO.iloc[:split_idx], featuresCO.iloc[split_idx:]\n",
    "y_train, y_test = targetCO.iloc[:split_idx], targetCO.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predCO = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseCO = mean_squared_error(y_test, y_predCO)\n",
    "r2CO = r2_score(y_test, y_predCO)\n",
    "maeCO = np.mean(np.abs(y_test - y_predCO))\n",
    "\n",
    "print(f\"Random Forest MSE: {mseCO:.4f}\")\n",
    "print(f\"Random Forest R2: {r2CO:.4f}\")\n",
    "print(f\"Random Forest MAE: {maeCO:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d7afc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean        2.088900\n",
      "std         1.182016\n",
      "min         0.100000\n",
      "25%         1.300000\n",
      "50%         2.127135\n",
      "75%         2.500000\n",
      "max         9.400000\n",
      "Name: CO(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "70a81f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NOx MSE: 20396.1630\n",
      "Random Forest NOx R2: 0.5779\n",
      "Random Forest NOx MAE: 96.4616\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NOx prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresNOx) * 0.8)\n",
    "X_train, X_test = featuresNOx.iloc[:split_idx], featuresNOx.iloc[split_idx:]\n",
    "y_train, y_test = targetNOx.iloc[:split_idx], targetNOx.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNOx = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNOx = mean_squared_error(y_test, y_predNOx)\n",
    "r2NOx = r2_score(y_test, y_predNOx)\n",
    "maeNOx = np.mean(np.abs(y_test - y_predNOx))\n",
    "\n",
    "print(f\"Random Forest NOx MSE: {mseNOx:.4f}\")\n",
    "print(f\"Random Forest NOx R2: {r2NOx:.4f}\")\n",
    "print(f\"Random Forest NOx MAE: {maeNOx:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5e4251b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean      209.267368\n",
      "std       153.067881\n",
      "min         2.000000\n",
      "25%        98.000000\n",
      "50%       203.500000\n",
      "75%       239.202722\n",
      "max      1247.000000\n",
      "Name: NOx(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "61fe63ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NMHC MSE: 3988.0399\n",
      "Random Forest NMHC R2: -4936954284135370029490853904384.0000\n",
      "Random Forest NMHC MAE: 41.5488\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NMHC prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresNMHC) * 0.8)\n",
    "X_train, X_test = featuresNMHC.iloc[:split_idx], featuresNMHC.iloc[split_idx:]\n",
    "y_train, y_test = targetNMHC.iloc[:split_idx], targetNMHC.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNMHC = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNMHC = mean_squared_error(y_test, y_predNMHC)\n",
    "r2NMHC = r2_score(y_test, y_predNMHC)\n",
    "maeNMHC = np.mean(np.abs(y_test - y_predNMHC))\n",
    "\n",
    "print(f\"Random Forest NMHC MSE: {mseNMHC:.4f}\")\n",
    "print(f\"Random Forest NMHC R2: {r2NMHC:.4f}\")\n",
    "print(f\"Random Forest NMHC MAE: {maeNMHC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "24622433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean      205.751701\n",
      "std        76.105317\n",
      "min         7.000000\n",
      "25%       205.751701\n",
      "50%       205.751701\n",
      "75%       205.751701\n",
      "max      1084.000000\n",
      "Name: NMHC(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "40bc45e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NO2 MSE: 1670.3740\n",
      "Random Forest NO2 R2: 0.3507\n",
      "Random Forest NO2 MAE: 29.5535\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NO2 prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_index = int(0.8 * len(data))\n",
    "X_train, X_test = featuresNO2.iloc[:split_index], featuresNO2.iloc[split_index:]\n",
    "y_train, y_test = targetNO2.iloc[:split_index], targetNO2.iloc[split_index:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNO2 = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNO2 = mean_squared_error(y_test, y_predNO2)\n",
    "r2NO2 = r2_score(y_test, y_predNO2)\n",
    "maeNO2 = np.mean(np.abs(y_test - y_predNO2))\n",
    "\n",
    "print(f\"Random Forest NO2 MSE: {mseNO2:.4f}\")\n",
    "print(f\"Random Forest NO2 R2: {r2NO2:.4f}\")\n",
    "print(f\"Random Forest NO2 MAE: {maeNO2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bdf93610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean      100.014217\n",
      "std        33.850669\n",
      "min         5.000000\n",
      "25%        76.000000\n",
      "50%       110.384952\n",
      "75%       114.000000\n",
      "max       233.000000\n",
      "Name: NO2(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d1114a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest C6H6 MSE: 0.0009\n",
      "Random Forest C6H6 R2: 1.0000\n",
      "Random Forest C6H6 MAE: 0.0129\n"
     ]
    }
   ],
   "source": [
    "# Random forest for C6H6 prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresC6H6) * 0.8)\n",
    "X_train, X_test = featuresC6H6.iloc[:split_idx], featuresC6H6.iloc[split_idx:]\n",
    "y_train, y_test = targetC6H6.iloc[:split_idx], targetC6H6.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predC6H6 = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseC6H6 = mean_squared_error(y_test, y_predC6H6)\n",
    "r2C6H6 = r2_score(y_test, y_predC6H6)\n",
    "maeC6H6 = np.mean(np.abs(y_test - y_predC6H6))\n",
    "\n",
    "print(f\"Random Forest C6H6 MSE: {mseC6H6:.4f}\")\n",
    "print(f\"Random Forest C6H6 R2: {r2C6H6:.4f}\")\n",
    "print(f\"Random Forest C6H6 MAE: {maeC6H6:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ff384276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean       10.322155\n",
      "std         7.174877\n",
      "min         0.200000\n",
      "25%         5.000000\n",
      "50%         8.850000\n",
      "75%        13.800000\n",
      "max        48.200000\n",
      "Name: C6H6(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c84efb",
   "metadata": {},
   "source": [
    "### LSTM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "507fb7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Year_2005</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Season_spring</th>\n",
       "      <th>Season_summer</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1143.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>825.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1186.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>976.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1192.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1536.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1592.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>1128.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>740.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>1064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>1015.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>608.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>979.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>0.8329</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>547.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>979.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>0.8329</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>547.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>1015.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>608.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7666 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PT08.S1(CO)     T    RH      AH  Year_2005  Day  DayOfWeek  IsWeekend  \\\n",
       "0          1143.0  12.0  61.6  0.8593      False    4          6          1   \n",
       "1          1186.0  15.8  48.0  0.8569      False    4          6          1   \n",
       "2          1192.0  16.8  44.0  0.8341      False    4          6          1   \n",
       "3          1536.0  18.3  40.9  0.8493      False    4          6          1   \n",
       "4          1592.0  20.8  36.7  0.8878      False    4          6          1   \n",
       "...           ...   ...   ...     ...        ...  ...        ...        ...   \n",
       "7661       1128.0  10.2  57.9  0.7191       True    3          5          1   \n",
       "7662       1015.0  10.3  59.4  0.7459       True    3          5          1   \n",
       "7663        979.0   9.8  68.9  0.8329       True    3          5          1   \n",
       "7664        979.0   9.8  68.9  0.8329       True    3          5          1   \n",
       "7665       1015.0  10.3  59.4  0.7459       True    3          5          1   \n",
       "\n",
       "      Hour_sin  Hour_cos     Month_sin  Month_cos  Season_spring  \\\n",
       "0     0.000000  1.000000  5.000000e-01   0.866025          False   \n",
       "1    -0.500000  0.866025  5.000000e-01   0.866025          False   \n",
       "2    -0.707107  0.707107  5.000000e-01   0.866025          False   \n",
       "3    -0.866025  0.500000  5.000000e-01   0.866025          False   \n",
       "4    -0.965926  0.258819  5.000000e-01   0.866025          False   \n",
       "...        ...       ...           ...        ...            ...   \n",
       "7661  0.707107  0.707107 -2.449294e-16   1.000000          False   \n",
       "7662  0.866025  0.500000 -2.449294e-16   1.000000          False   \n",
       "7663  0.965926  0.258819 -2.449294e-16   1.000000          False   \n",
       "7664  0.965926  0.258819 -2.449294e-16   1.000000          False   \n",
       "7665  0.866025  0.500000 -2.449294e-16   1.000000          False   \n",
       "\n",
       "      Season_summer  PT08.S2(NMHC)  PT08.S3(NOx)  PT08.S4(NO2)  PT08.S5(O3)  \n",
       "0             False          825.0         986.0        1477.0        978.0  \n",
       "1             False          976.0         844.0        1570.0       1200.0  \n",
       "2             False         1007.0         827.0        1604.0       1223.0  \n",
       "3             False         1302.0         666.0        1922.0       1599.0  \n",
       "4             False         1429.0         624.0        2089.0       1644.0  \n",
       "...             ...            ...           ...           ...          ...  \n",
       "7661          False          740.0         705.0        1113.0       1064.0  \n",
       "7662          False          608.0         873.0        1027.0        655.0  \n",
       "7663          False          547.0         952.0        1039.0        470.0  \n",
       "7664          False          547.0         952.0        1039.0        470.0  \n",
       "7665          False          608.0         873.0        1027.0        655.0  \n",
       "\n",
       "[7666 rows x 18 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "121095db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0210 - val_loss: 0.0141\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0110\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0116\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0075 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0075 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0073 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0138\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0118\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step \n",
      "LSTM CO RMSE: 1.2879\n",
      "LSTM CO R2: 0.1380\n",
      "LSTM CO MAE: 0.9313\n"
     ]
    }
   ],
   "source": [
    "#LSTM pred for CO\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresCO.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetCO.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse scale to original CO values\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMCO = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R\n",
    "r2LSTMCO = r2_score(y_test_inv, y_pred_inv)\n",
    "# Calculate MAE\n",
    "maeLSTMCO = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM CO RMSE: {rmseLSTMCO:.4f}\")\n",
    "print(f\"LSTM CO R2: {r2LSTMCO:.4f}\")\n",
    "print(f\"LSTM CO MAE: {maeLSTMCO:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "77fa7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0119 - val_loss: 0.0190\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0192\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0184\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0238\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0231\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0231\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0221\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0264\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0257\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0063 - val_loss: 0.0290\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0281\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0252\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0268\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0304\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0314\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0309\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0288\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0328\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0327\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0282\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0271\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0253\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0287\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0257\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0282\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0281\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0314\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0289\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0253\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0298\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0261\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0309\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0243\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0243\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0264\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0273\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0277\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0263\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0223\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0270\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0256\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0243\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0262\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0268\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0228\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0235\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0254\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0279\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0228\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM NOx RMSE: 286.7668\n",
      "LSTM NOx R2: -0.7006\n",
      "LSTM NOx MAE: 208.0825\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NOx\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresNOx.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNOx.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split  =0.1)\n",
    "\n",
    "# Predict \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNOx = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R\n",
    "r2LSTMNOx = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNOx = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NOx RMSE: {rmseLSTMNOx:.4f}\")\n",
    "print(f\"LSTM NOx R2: {r2LSTMNOx:.4f}\")\n",
    "print(f\"LSTM NOx MAE: {maeLSTMNOx:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d5fa8a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0081\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0097\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0115\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0109\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0108\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0136\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0097\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0137\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0168\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0096\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - val_loss: 0.0087\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0153\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0097\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0099\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0092\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0100\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0086\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0107\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "LSTM NMHC RMSE: 128.5150\n",
      "LSTM NMHC R2: -20445938584998393771816032141312.0000\n",
      "LSTM NMHC MAE: 111.4681\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NMHC\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresNMHC.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNMHC.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNMHC = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R\n",
    "r2LSTMNMHC = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNMHC = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NMHC RMSE: {rmseLSTMNMHC:.4f}\")\n",
    "print(f\"LSTM NMHC R2: {r2LSTMNMHC:.4f}\")\n",
    "print(f\"LSTM NMHC MAE: {maeLSTMNMHC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c7202832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0171\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0171\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0155\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0151\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0153\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0149\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0159\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0143\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0106\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0140\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0142\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0143\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0139\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0137\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0126\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0114\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0126\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0117\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0146\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0121\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0117\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0162\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "LSTM NO2 RMSE: 77.7275\n",
      "LSTM NO2 R2: -1.3472\n",
      "LSTM NO2 MAE: 63.8348\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NO2\n",
    "# Features (all numeric columns)\n",
    "X = featuresNO2.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNO2.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNO2 = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R\n",
    "r2LSTMNO2 = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNO2 = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NO2 RMSE: {rmseLSTMNO2:.4f}\")\n",
    "print(f\"LSTM NO2 R2: {r2LSTMNO2:.4f}\")\n",
    "print(f\"LSTM NO2 MAE: {maeLSTMNO2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "be118b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "LSTM C6H6 RMSE: 6.0739\n",
      "LSTM C6H6 R2: -0.0138\n",
      "LSTM C6H6 MAE: 4.5592\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for C6H6\n",
    "# Features (all numeric columns)\n",
    "X = featuresC6H6.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetC6H6.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1) \n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMC6H6 = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R\n",
    "r2LSTMC6H6 = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMC6H6 = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM C6H6 RMSE: {rmseLSTMC6H6:.4f}\")\n",
    "print(f\"LSTM C6H6 R2: {r2LSTMC6H6:.4f}\")\n",
    "print(f\"LSTM C6H6 MAE: {maeLSTMC6H6:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af9b56",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "01abfadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_RMSE</th>\n",
       "      <th>Baseline_R2</th>\n",
       "      <th>Baseline_MAE</th>\n",
       "      <th>RandomForest_RMSE</th>\n",
       "      <th>RandomForest_R2</th>\n",
       "      <th>RandomForest_MAE</th>\n",
       "      <th>LSTM_RMSE</th>\n",
       "      <th>LSTM_R2</th>\n",
       "      <th>LSTM_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT)</th>\n",
       "      <td>1.141277</td>\n",
       "      <td>0.243215</td>\n",
       "      <td>0.684330</td>\n",
       "      <td>0.804571</td>\n",
       "      <td>6.632457e-01</td>\n",
       "      <td>0.538787</td>\n",
       "      <td>1.287906</td>\n",
       "      <td>1.379575e-01</td>\n",
       "      <td>0.931257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <td>33.390092</td>\n",
       "      <td>0.313139</td>\n",
       "      <td>3.736177</td>\n",
       "      <td>0.029435</td>\n",
       "      <td>9.999762e-01</td>\n",
       "      <td>0.012937</td>\n",
       "      <td>6.073926</td>\n",
       "      <td>-1.376585e-02</td>\n",
       "      <td>4.559173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <td>3126.714984</td>\n",
       "      <td>0.324911</td>\n",
       "      <td>12.280400</td>\n",
       "      <td>63.150930</td>\n",
       "      <td>-4.936954e+30</td>\n",
       "      <td>41.548760</td>\n",
       "      <td>128.514971</td>\n",
       "      <td>-2.044594e+31</td>\n",
       "      <td>111.468115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOx(GT)</th>\n",
       "      <td>17431.584722</td>\n",
       "      <td>0.455097</td>\n",
       "      <td>78.551155</td>\n",
       "      <td>142.815136</td>\n",
       "      <td>5.778612e-01</td>\n",
       "      <td>96.461562</td>\n",
       "      <td>286.766760</td>\n",
       "      <td>-7.006490e-01</td>\n",
       "      <td>208.082472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2(GT)</th>\n",
       "      <td>1030.288784</td>\n",
       "      <td>0.446477</td>\n",
       "      <td>21.128452</td>\n",
       "      <td>40.870209</td>\n",
       "      <td>3.507364e-01</td>\n",
       "      <td>29.553529</td>\n",
       "      <td>77.727528</td>\n",
       "      <td>-1.347183e+00</td>\n",
       "      <td>63.834798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_RMSE  Baseline_R2  Baseline_MAE  RandomForest_RMSE  \\\n",
       "CO(GT)         1.141277     0.243215      0.684330           0.804571   \n",
       "C6H6(GT)      33.390092     0.313139      3.736177           0.029435   \n",
       "NMHC(GT)    3126.714984     0.324911     12.280400          63.150930   \n",
       "NOx(GT)    17431.584722     0.455097     78.551155         142.815136   \n",
       "NO2(GT)     1030.288784     0.446477     21.128452          40.870209   \n",
       "\n",
       "          RandomForest_R2  RandomForest_MAE   LSTM_RMSE       LSTM_R2  \\\n",
       "CO(GT)       6.632457e-01          0.538787    1.287906  1.379575e-01   \n",
       "C6H6(GT)     9.999762e-01          0.012937    6.073926 -1.376585e-02   \n",
       "NMHC(GT)    -4.936954e+30         41.548760  128.514971 -2.044594e+31   \n",
       "NOx(GT)      5.778612e-01         96.461562  286.766760 -7.006490e-01   \n",
       "NO2(GT)      3.507364e-01         29.553529   77.727528 -1.347183e+00   \n",
       "\n",
       "            LSTM_MAE  \n",
       "CO(GT)      0.931257  \n",
       "C6H6(GT)    4.559173  \n",
       "NMHC(GT)  111.468115  \n",
       "NOx(GT)   208.082472  \n",
       "NO2(GT)    63.834798  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect metrics for each chemical and method\n",
    "\n",
    "# Baseline\n",
    "baseline_metrics = baseline_results_df[['RMSE', 'R2', 'MAE']].copy()\n",
    "baseline_metrics.columns = ['Baseline_RMSE', 'Baseline_R2', 'Baseline_MAE']\n",
    "\n",
    "# Random Forest\n",
    "rf_metrics = pd.DataFrame({\n",
    "    'RandomForest_RMSE': [\n",
    "        mseCO**0.5, mseC6H6**0.5, mseNMHC**0.5, mseNOx**0.5, mseNO2**0.5\n",
    "    ],\n",
    "    'RandomForest_R2': [\n",
    "        r2CO, r2C6H6, r2NMHC, r2NOx, r2NO2\n",
    "    ],\n",
    "    'RandomForest_MAE': [\n",
    "        maeCO, maeC6H6, maeNMHC, maeNOx, maeNO2\n",
    "    ]\n",
    "}, index=baseline_metrics.index)\n",
    "\n",
    "# LSTM\n",
    "lstm_metrics = pd.DataFrame({\n",
    "    'LSTM_RMSE': [\n",
    "        rmseLSTMCO, rmseLSTMC6H6, rmseLSTMNMHC, rmseLSTMNOx, rmseLSTMNO2\n",
    "    ],\n",
    "    'LSTM_R2': [\n",
    "        r2LSTMCO, r2LSTMC6H6, r2LSTMNMHC, r2LSTMNOx, r2LSTMNO2\n",
    "    ],\n",
    "    'LSTM_MAE': [\n",
    "        maeLSTMCO, maeLSTMC6H6, maeLSTMNMHC, maeLSTMNOx, maeLSTMNO2\n",
    "    ]\n",
    "}, index=baseline_metrics.index)\n",
    "\n",
    "# Combine all metrics\n",
    "results_df = pd.concat([baseline_metrics, rf_metrics, lstm_metrics], axis=1)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
