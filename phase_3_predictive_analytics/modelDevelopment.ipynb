{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2530cd2a",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8351ef",
   "metadata": {},
   "source": [
    "### Prepping data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "eacc6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.75.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.10.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow scikit-learn pandas matplotlib seaborn numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9b2ce5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "833be42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>825.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>976.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0  2004-01-04   0:00:00     1.6       1143.0     106.0       6.3   \n",
       "1  2004-01-04  22:00:00     2.0       1186.0     188.0       9.9   \n",
       "2  2004-01-04  21:00:00     2.5       1192.0     254.0      10.8   \n",
       "3  2004-01-04  20:00:00     4.9       1536.0     655.0      20.2   \n",
       "4  2004-01-04  19:00:00     5.5       1592.0     840.0      25.0   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0          825.0     96.0         986.0     86.0        1477.0        978.0   \n",
       "1          976.0    127.0         844.0    113.0        1570.0       1200.0   \n",
       "2         1007.0    154.0         827.0    124.0        1604.0       1223.0   \n",
       "3         1302.0    269.0         666.0    161.0        1922.0       1599.0   \n",
       "4         1429.0    267.0         624.0    164.0        2089.0       1644.0   \n",
       "\n",
       "      T    RH      AH year_month  \n",
       "0  12.0  61.6  0.8593    2004-01  \n",
       "1  15.8  48.0  0.8569    2004-01  \n",
       "2  16.8  44.0  0.8341    2004-01  \n",
       "3  18.3  40.9  0.8493    2004-01  \n",
       "4  20.8  36.7  0.8878    2004-01  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all the CSV files in the directory\n",
    "data_dir = '../data'\n",
    "all_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "df_list = [pd.read_csv(f) for f in all_files]\n",
    "data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Sort by datatimestamp\n",
    "data = data.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "509463c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                0\n",
       "Time                0\n",
       "CO(GT)           1283\n",
       "PT08.S1(CO)       385\n",
       "NMHC(GT)         6784\n",
       "C6H6(GT)          385\n",
       "PT08.S2(NMHC)     385\n",
       "NOx(GT)          1495\n",
       "PT08.S3(NOx)      385\n",
       "NO2(GT)          1499\n",
       "PT08.S4(NO2)      385\n",
       "PT08.S5(O3)       385\n",
       "T                 385\n",
       "RH                385\n",
       "AH                385\n",
       "year_month          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba128bf2",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "655a9d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>825.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>976.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  \\\n",
       "0     1.6       1143.0     106.0       6.3          825.0     96.0   \n",
       "1     2.0       1186.0     188.0       9.9          976.0    127.0   \n",
       "2     2.5       1192.0     254.0      10.8         1007.0    154.0   \n",
       "3     4.9       1536.0     655.0      20.2         1302.0    269.0   \n",
       "4     5.5       1592.0     840.0      25.0         1429.0    267.0   \n",
       "\n",
       "   PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  Year  \\\n",
       "0         986.0     86.0        1477.0        978.0  12.0  61.6  0.8593  2004   \n",
       "1         844.0    113.0        1570.0       1200.0  15.8  48.0  0.8569  2004   \n",
       "2         827.0    124.0        1604.0       1223.0  16.8  44.0  0.8341  2004   \n",
       "3         666.0    161.0        1922.0       1599.0  18.3  40.9  0.8493  2004   \n",
       "4         624.0    164.0        2089.0       1644.0  20.8  36.7  0.8878  2004   \n",
       "\n",
       "   Month  Day  DayOfWeek  IsWeekend  Hour  \n",
       "0      1    4          6          1     0  \n",
       "1      1    4          6          1    22  \n",
       "2      1    4          6          1    21  \n",
       "3      1    4          6          1    20  \n",
       "4      1    4          6          1    19  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Date related columns from 'Date' column\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
    "data['IsWeekend'] = data['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Convert time column to datetime\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S')\n",
    "data['Hour'] = data['Time'].dt.hour\n",
    "\n",
    "data = data.drop(columns=['Time', 'year_month', 'Date'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "825f1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Season column\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "data['Season'] = data['Month'].apply(get_season)\n",
    "\n",
    "# One-hot encoding for Season\n",
    "data = pd.get_dummies(data, columns=['Season'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a0c103e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for Year\n",
    "data = pd.get_dummies(data, columns=['Year'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7565c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical Encoding for hour\n",
    "data['Hour_sin'] = np.sin(2 * np.pi * data['Hour'] / 24)\n",
    "data['Hour_cos'] = np.cos(2 * np.pi * data['Hour'] / 24)\n",
    "data = data.drop(columns=['Hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "294135c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycilical Encoding for Month\n",
    "data['Month_sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
    "data['Month_cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
    "data = data.drop(columns=['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c026d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "688f41dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)',\n",
       "       'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)',\n",
       "       'T', 'RH', 'AH', 'Day', 'DayOfWeek', 'IsWeekend', 'Season_spring',\n",
       "       'Season_summer', 'Season_winter', 'Year_2005', 'Hour_sin', 'Hour_cos',\n",
       "       'Month_sin', 'Month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff804e3",
   "metadata": {},
   "source": [
    "### Baseline Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "54252daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT)</th>\n",
       "      <td>0.684330</td>\n",
       "      <td>1.141277</td>\n",
       "      <td>0.243215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <td>3.736177</td>\n",
       "      <td>33.390092</td>\n",
       "      <td>0.313139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <td>12.280400</td>\n",
       "      <td>3126.714984</td>\n",
       "      <td>0.324911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOx(GT)</th>\n",
       "      <td>78.551155</td>\n",
       "      <td>17431.584722</td>\n",
       "      <td>0.455097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2(GT)</th>\n",
       "      <td>21.128452</td>\n",
       "      <td>1030.288784</td>\n",
       "      <td>0.446477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MAE          RMSE        R2\n",
       "CO(GT)     0.684330      1.141277  0.243215\n",
       "C6H6(GT)   3.736177     33.390092  0.313139\n",
       "NMHC(GT)  12.280400   3126.714984  0.324911\n",
       "NOx(GT)   78.551155  17431.584722  0.455097\n",
       "NO2(GT)   21.128452   1030.288784  0.446477"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive pred using prev value\n",
    "targets = ['CO(GT)', 'C6H6(GT)', 'NMHC(GT)', 'NOx(GT)', 'NO2(GT)']  # add others as needed\n",
    "baseline_results = {}\n",
    "\n",
    "for target in targets:\n",
    "    y = data[target].fillna(method='ffill')  \n",
    "    y_pred = y.shift(1).iloc[1:]            \n",
    "    y_true = y.iloc[1:]\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    baseline_results[target] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "    \n",
    "baseline_results_df = pd.DataFrame(baseline_results).T\n",
    "baseline_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605fcd2",
   "metadata": {},
   "source": [
    "### Define Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6a63a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (CO)\n",
    "targetCO = data['CO(GT)']\n",
    "otherSensorsCO = ['PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresCO = data[['PT08.S1(CO)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsCO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3640d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NOx)\n",
    "targetNOx = data['NOx(GT)']\n",
    "otherSensorsNOx = ['PT08.S2(NMHC)', 'PT08.S1(CO)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresNOx = data[['PT08.S3(NOx)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNOx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f1e6c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NMHC)\n",
    "targetNMHC = data['NMHC(GT)']\n",
    "otherSensorsNMHC = ['PT08.S1(CO)', 'PT08.S3(NOx)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresNMHC = data[['PT08.S2(NMHC)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNMHC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "50df5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NO2)\n",
    "targetNO2 = data['NO2(GT)']\n",
    "otherSensorsNO2 = ['PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S5(O3)']\n",
    "featuresNO2 = data[['PT08.S4(NO2)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNO2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e8bc357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (C6H6)\n",
    "targetC6H6 = data['C6H6(GT)']\n",
    "otherSensorsC6H6 = ['PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)']\n",
    "featuresC6H6 = data[['PT08.S5(O3)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsC6H6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40c3b6",
   "metadata": {},
   "source": [
    "### Random Forest for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "46e89030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.6473\n",
      "Random Forest R2: 0.6632\n",
      "Random Forest MAE: 0.5388\n"
     ]
    }
   ],
   "source": [
    "# Random forest for CO prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresCO) * 0.8)\n",
    "X_train, X_test = featuresCO.iloc[:split_idx], featuresCO.iloc[split_idx:]\n",
    "y_train, y_test = targetCO.iloc[:split_idx], targetCO.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predCO = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseCO = mean_squared_error(y_test, y_predCO)\n",
    "r2CO = r2_score(y_test, y_predCO)\n",
    "maeCO = np.mean(np.abs(y_test - y_predCO))\n",
    "\n",
    "print(f\"Random Forest MSE: {mseCO:.4f}\")\n",
    "print(f\"Random Forest R2: {r2CO:.4f}\")\n",
    "print(f\"Random Forest MAE: {maeCO:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d7afc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean        2.088900\n",
      "std         1.182016\n",
      "min         0.100000\n",
      "25%         1.300000\n",
      "50%         2.127135\n",
      "75%         2.500000\n",
      "max         9.400000\n",
      "Name: CO(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "70a81f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NOx MSE: 20396.1630\n",
      "Random Forest NOx R2: 0.5779\n",
      "Random Forest NOx MAE: 96.4616\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NOx prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresNOx) * 0.8)\n",
    "X_train, X_test = featuresNOx.iloc[:split_idx], featuresNOx.iloc[split_idx:]\n",
    "y_train, y_test = targetNOx.iloc[:split_idx], targetNOx.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNOx = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNOx = mean_squared_error(y_test, y_predNOx)\n",
    "r2NOx = r2_score(y_test, y_predNOx)\n",
    "maeNOx = np.mean(np.abs(y_test - y_predNOx))\n",
    "\n",
    "print(f\"Random Forest NOx MSE: {mseNOx:.4f}\")\n",
    "print(f\"Random Forest NOx R2: {r2NOx:.4f}\")\n",
    "print(f\"Random Forest NOx MAE: {maeNOx:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5e4251b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean      209.267368\n",
      "std       153.067881\n",
      "min         2.000000\n",
      "25%        98.000000\n",
      "50%       203.500000\n",
      "75%       239.202722\n",
      "max      1247.000000\n",
      "Name: NOx(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "61fe63ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NMHC MSE: 3988.0399\n",
      "Random Forest NMHC R2: -4936954284135370029490853904384.0000\n",
      "Random Forest NMHC MAE: 41.5488\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NMHC prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresNMHC) * 0.8)\n",
    "X_train, X_test = featuresNMHC.iloc[:split_idx], featuresNMHC.iloc[split_idx:]\n",
    "y_train, y_test = targetNMHC.iloc[:split_idx], targetNMHC.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNMHC = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNMHC = mean_squared_error(y_test, y_predNMHC)\n",
    "r2NMHC = r2_score(y_test, y_predNMHC)\n",
    "maeNMHC = np.mean(np.abs(y_test - y_predNMHC))\n",
    "\n",
    "print(f\"Random Forest NMHC MSE: {mseNMHC:.4f}\")\n",
    "print(f\"Random Forest NMHC R2: {r2NMHC:.4f}\")\n",
    "print(f\"Random Forest NMHC MAE: {maeNMHC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "24622433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean      205.751701\n",
      "std        76.105317\n",
      "min         7.000000\n",
      "25%       205.751701\n",
      "50%       205.751701\n",
      "75%       205.751701\n",
      "max      1084.000000\n",
      "Name: NMHC(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "40bc45e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NO2 MSE: 1670.3740\n",
      "Random Forest NO2 R2: 0.3507\n",
      "Random Forest NO2 MAE: 29.5535\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NO2 prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_index = int(0.8 * len(data))\n",
    "X_train, X_test = featuresNO2.iloc[:split_index], featuresNO2.iloc[split_index:]\n",
    "y_train, y_test = targetNO2.iloc[:split_index], targetNO2.iloc[split_index:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNO2 = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNO2 = mean_squared_error(y_test, y_predNO2)\n",
    "r2NO2 = r2_score(y_test, y_predNO2)\n",
    "maeNO2 = np.mean(np.abs(y_test - y_predNO2))\n",
    "\n",
    "print(f\"Random Forest NO2 MSE: {mseNO2:.4f}\")\n",
    "print(f\"Random Forest NO2 R2: {r2NO2:.4f}\")\n",
    "print(f\"Random Forest NO2 MAE: {maeNO2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bdf93610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean      100.014217\n",
      "std        33.850669\n",
      "min         5.000000\n",
      "25%        76.000000\n",
      "50%       110.384952\n",
      "75%       114.000000\n",
      "max       233.000000\n",
      "Name: NO2(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d1114a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest C6H6 MSE: 0.0009\n",
      "Random Forest C6H6 R2: 1.0000\n",
      "Random Forest C6H6 MAE: 0.0129\n"
     ]
    }
   ],
   "source": [
    "# Random forest for C6H6 prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresC6H6) * 0.8)\n",
    "X_train, X_test = featuresC6H6.iloc[:split_idx], featuresC6H6.iloc[split_idx:]\n",
    "y_train, y_test = targetC6H6.iloc[:split_idx], targetC6H6.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predC6H6 = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseC6H6 = mean_squared_error(y_test, y_predC6H6)\n",
    "r2C6H6 = r2_score(y_test, y_predC6H6)\n",
    "maeC6H6 = np.mean(np.abs(y_test - y_predC6H6))\n",
    "\n",
    "print(f\"Random Forest C6H6 MSE: {mseC6H6:.4f}\")\n",
    "print(f\"Random Forest C6H6 R2: {r2C6H6:.4f}\")\n",
    "print(f\"Random Forest C6H6 MAE: {maeC6H6:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ff384276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6132.000000\n",
      "mean       10.322155\n",
      "std         7.174877\n",
      "min         0.200000\n",
      "25%         5.000000\n",
      "50%         8.850000\n",
      "75%        13.800000\n",
      "max        48.200000\n",
      "Name: C6H6(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c84efb",
   "metadata": {},
   "source": [
    "### LSTM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "507fb7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Year_2005</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Season_spring</th>\n",
       "      <th>Season_summer</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1143.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>825.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1186.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>976.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1192.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1536.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>1599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1592.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>1128.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>740.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>1064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>1015.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>608.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>979.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>0.8329</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>547.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>979.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>0.8329</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>547.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>1015.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>608.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7666 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PT08.S1(CO)     T    RH      AH  Year_2005  Day  DayOfWeek  IsWeekend  \\\n",
       "0          1143.0  12.0  61.6  0.8593      False    4          6          1   \n",
       "1          1186.0  15.8  48.0  0.8569      False    4          6          1   \n",
       "2          1192.0  16.8  44.0  0.8341      False    4          6          1   \n",
       "3          1536.0  18.3  40.9  0.8493      False    4          6          1   \n",
       "4          1592.0  20.8  36.7  0.8878      False    4          6          1   \n",
       "...           ...   ...   ...     ...        ...  ...        ...        ...   \n",
       "7661       1128.0  10.2  57.9  0.7191       True    3          5          1   \n",
       "7662       1015.0  10.3  59.4  0.7459       True    3          5          1   \n",
       "7663        979.0   9.8  68.9  0.8329       True    3          5          1   \n",
       "7664        979.0   9.8  68.9  0.8329       True    3          5          1   \n",
       "7665       1015.0  10.3  59.4  0.7459       True    3          5          1   \n",
       "\n",
       "      Hour_sin  Hour_cos     Month_sin  Month_cos  Season_spring  \\\n",
       "0     0.000000  1.000000  5.000000e-01   0.866025          False   \n",
       "1    -0.500000  0.866025  5.000000e-01   0.866025          False   \n",
       "2    -0.707107  0.707107  5.000000e-01   0.866025          False   \n",
       "3    -0.866025  0.500000  5.000000e-01   0.866025          False   \n",
       "4    -0.965926  0.258819  5.000000e-01   0.866025          False   \n",
       "...        ...       ...           ...        ...            ...   \n",
       "7661  0.707107  0.707107 -2.449294e-16   1.000000          False   \n",
       "7662  0.866025  0.500000 -2.449294e-16   1.000000          False   \n",
       "7663  0.965926  0.258819 -2.449294e-16   1.000000          False   \n",
       "7664  0.965926  0.258819 -2.449294e-16   1.000000          False   \n",
       "7665  0.866025  0.500000 -2.449294e-16   1.000000          False   \n",
       "\n",
       "      Season_summer  PT08.S2(NMHC)  PT08.S3(NOx)  PT08.S4(NO2)  PT08.S5(O3)  \n",
       "0             False          825.0         986.0        1477.0        978.0  \n",
       "1             False          976.0         844.0        1570.0       1200.0  \n",
       "2             False         1007.0         827.0        1604.0       1223.0  \n",
       "3             False         1302.0         666.0        1922.0       1599.0  \n",
       "4             False         1429.0         624.0        2089.0       1644.0  \n",
       "...             ...            ...           ...           ...          ...  \n",
       "7661          False          740.0         705.0        1113.0       1064.0  \n",
       "7662          False          608.0         873.0        1027.0        655.0  \n",
       "7663          False          547.0         952.0        1039.0        470.0  \n",
       "7664          False          547.0         952.0        1039.0        470.0  \n",
       "7665          False          608.0         873.0        1027.0        655.0  \n",
       "\n",
       "[7666 rows x 18 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "121095db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0210 - val_loss: 0.0141\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0110\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0116\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0075 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0075 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0073 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0138\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0118\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step \n",
      "LSTM CO RMSE: 1.2879\n",
      "LSTM CO R2: 0.1380\n",
      "LSTM CO MAE: 0.9313\n"
     ]
    }
   ],
   "source": [
    "#LSTM pred for CO\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresCO.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetCO.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse scale to original CO values\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMCO = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMCO = r2_score(y_test_inv, y_pred_inv)\n",
    "# Calculate MAE\n",
    "maeLSTMCO = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM CO RMSE: {rmseLSTMCO:.4f}\")\n",
    "print(f\"LSTM CO R2: {r2LSTMCO:.4f}\")\n",
    "print(f\"LSTM CO MAE: {maeLSTMCO:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "77fa7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0119 - val_loss: 0.0190\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0192\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0184\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0238\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0231\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0231\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0221\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0264\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0257\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0063 - val_loss: 0.0290\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0281\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0252\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0268\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0304\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0314\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0309\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0288\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0328\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0327\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0282\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0271\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0253\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0287\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0257\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0282\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0281\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0314\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0289\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0253\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0298\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0261\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0309\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0243\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0243\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0264\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0273\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0277\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0263\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0223\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0270\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0256\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0243\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0262\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0268\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0228\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0235\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0254\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0279\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0228\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM NOx RMSE: 286.7668\n",
      "LSTM NOx R2: -0.7006\n",
      "LSTM NOx MAE: 208.0825\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NOx\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresNOx.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNOx.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split  =0.1)\n",
    "\n",
    "# Predict \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNOx = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMNOx = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNOx = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NOx RMSE: {rmseLSTMNOx:.4f}\")\n",
    "print(f\"LSTM NOx R2: {r2LSTMNOx:.4f}\")\n",
    "print(f\"LSTM NOx MAE: {maeLSTMNOx:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d5fa8a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0081\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0097\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0115\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0109\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0108\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0136\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0097\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0137\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0168\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0096\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - val_loss: 0.0087\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0153\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0097\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0099\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0092\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0100\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0086\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0107\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "LSTM NMHC RMSE: 128.5150\n",
      "LSTM NMHC R2: -20445938584998393771816032141312.0000\n",
      "LSTM NMHC MAE: 111.4681\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NMHC\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresNMHC.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNMHC.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNMHC = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMNMHC = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNMHC = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NMHC RMSE: {rmseLSTMNMHC:.4f}\")\n",
    "print(f\"LSTM NMHC R2: {r2LSTMNMHC:.4f}\")\n",
    "print(f\"LSTM NMHC MAE: {maeLSTMNMHC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c7202832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0171\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0171\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0155\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0151\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0153\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0149\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0159\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0143\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0106\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0140\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0142\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0143\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0139\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0137\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0126\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0114\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0126\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0117\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0146\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0121\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0117\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0162\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "LSTM NO2 RMSE: 77.7275\n",
      "LSTM NO2 R2: -1.3472\n",
      "LSTM NO2 MAE: 63.8348\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NO2\n",
    "# Features (all numeric columns)\n",
    "X = featuresNO2.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNO2.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNO2 = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMNO2 = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNO2 = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NO2 RMSE: {rmseLSTMNO2:.4f}\")\n",
    "print(f\"LSTM NO2 R2: {r2LSTMNO2:.4f}\")\n",
    "print(f\"LSTM NO2 MAE: {maeLSTMNO2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "be118b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "LSTM C6H6 RMSE: 6.0739\n",
      "LSTM C6H6 R2: -0.0138\n",
      "LSTM C6H6 MAE: 4.5592\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for C6H6\n",
    "# Features (all numeric columns)\n",
    "X = featuresC6H6.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetC6H6.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1) \n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMC6H6 = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMC6H6 = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMC6H6 = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM C6H6 RMSE: {rmseLSTMC6H6:.4f}\")\n",
    "print(f\"LSTM C6H6 R2: {r2LSTMC6H6:.4f}\")\n",
    "print(f\"LSTM C6H6 MAE: {maeLSTMC6H6:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af9b56",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "01abfadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_RMSE</th>\n",
       "      <th>Baseline_R2</th>\n",
       "      <th>Baseline_MAE</th>\n",
       "      <th>RandomForest_RMSE</th>\n",
       "      <th>RandomForest_R2</th>\n",
       "      <th>RandomForest_MAE</th>\n",
       "      <th>LSTM_RMSE</th>\n",
       "      <th>LSTM_R2</th>\n",
       "      <th>LSTM_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT)</th>\n",
       "      <td>1.141277</td>\n",
       "      <td>0.243215</td>\n",
       "      <td>0.684330</td>\n",
       "      <td>0.804571</td>\n",
       "      <td>6.632457e-01</td>\n",
       "      <td>0.538787</td>\n",
       "      <td>1.287906</td>\n",
       "      <td>1.379575e-01</td>\n",
       "      <td>0.931257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <td>33.390092</td>\n",
       "      <td>0.313139</td>\n",
       "      <td>3.736177</td>\n",
       "      <td>0.029435</td>\n",
       "      <td>9.999762e-01</td>\n",
       "      <td>0.012937</td>\n",
       "      <td>6.073926</td>\n",
       "      <td>-1.376585e-02</td>\n",
       "      <td>4.559173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <td>3126.714984</td>\n",
       "      <td>0.324911</td>\n",
       "      <td>12.280400</td>\n",
       "      <td>63.150930</td>\n",
       "      <td>-4.936954e+30</td>\n",
       "      <td>41.548760</td>\n",
       "      <td>128.514971</td>\n",
       "      <td>-2.044594e+31</td>\n",
       "      <td>111.468115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOx(GT)</th>\n",
       "      <td>17431.584722</td>\n",
       "      <td>0.455097</td>\n",
       "      <td>78.551155</td>\n",
       "      <td>142.815136</td>\n",
       "      <td>5.778612e-01</td>\n",
       "      <td>96.461562</td>\n",
       "      <td>286.766760</td>\n",
       "      <td>-7.006490e-01</td>\n",
       "      <td>208.082472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2(GT)</th>\n",
       "      <td>1030.288784</td>\n",
       "      <td>0.446477</td>\n",
       "      <td>21.128452</td>\n",
       "      <td>40.870209</td>\n",
       "      <td>3.507364e-01</td>\n",
       "      <td>29.553529</td>\n",
       "      <td>77.727528</td>\n",
       "      <td>-1.347183e+00</td>\n",
       "      <td>63.834798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_RMSE  Baseline_R2  Baseline_MAE  RandomForest_RMSE  \\\n",
       "CO(GT)         1.141277     0.243215      0.684330           0.804571   \n",
       "C6H6(GT)      33.390092     0.313139      3.736177           0.029435   \n",
       "NMHC(GT)    3126.714984     0.324911     12.280400          63.150930   \n",
       "NOx(GT)    17431.584722     0.455097     78.551155         142.815136   \n",
       "NO2(GT)     1030.288784     0.446477     21.128452          40.870209   \n",
       "\n",
       "          RandomForest_R2  RandomForest_MAE   LSTM_RMSE       LSTM_R2  \\\n",
       "CO(GT)       6.632457e-01          0.538787    1.287906  1.379575e-01   \n",
       "C6H6(GT)     9.999762e-01          0.012937    6.073926 -1.376585e-02   \n",
       "NMHC(GT)    -4.936954e+30         41.548760  128.514971 -2.044594e+31   \n",
       "NOx(GT)      5.778612e-01         96.461562  286.766760 -7.006490e-01   \n",
       "NO2(GT)      3.507364e-01         29.553529   77.727528 -1.347183e+00   \n",
       "\n",
       "            LSTM_MAE  \n",
       "CO(GT)      0.931257  \n",
       "C6H6(GT)    4.559173  \n",
       "NMHC(GT)  111.468115  \n",
       "NOx(GT)   208.082472  \n",
       "NO2(GT)    63.834798  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect metrics for each chemical and method\n",
    "\n",
    "# Baseline\n",
    "baseline_metrics = baseline_results_df[['RMSE', 'R2', 'MAE']].copy()\n",
    "baseline_metrics.columns = ['Baseline_RMSE', 'Baseline_R2', 'Baseline_MAE']\n",
    "\n",
    "# Random Forest\n",
    "rf_metrics = pd.DataFrame({\n",
    "    'RandomForest_RMSE': [\n",
    "        mseCO**0.5, mseC6H6**0.5, mseNMHC**0.5, mseNOx**0.5, mseNO2**0.5\n",
    "    ],\n",
    "    'RandomForest_R2': [\n",
    "        r2CO, r2C6H6, r2NMHC, r2NOx, r2NO2\n",
    "    ],\n",
    "    'RandomForest_MAE': [\n",
    "        maeCO, maeC6H6, maeNMHC, maeNOx, maeNO2\n",
    "    ]\n",
    "}, index=baseline_metrics.index)\n",
    "\n",
    "# LSTM\n",
    "lstm_metrics = pd.DataFrame({\n",
    "    'LSTM_RMSE': [\n",
    "        rmseLSTMCO, rmseLSTMC6H6, rmseLSTMNMHC, rmseLSTMNOx, rmseLSTMNO2\n",
    "    ],\n",
    "    'LSTM_R2': [\n",
    "        r2LSTMCO, r2LSTMC6H6, r2LSTMNMHC, r2LSTMNOx, r2LSTMNO2\n",
    "    ],\n",
    "    'LSTM_MAE': [\n",
    "        maeLSTMCO, maeLSTMC6H6, maeLSTMNMHC, maeLSTMNOx, maeLSTMNO2\n",
    "    ]\n",
    "}, index=baseline_metrics.index)\n",
    "\n",
    "# Combine all metrics\n",
    "results_df = pd.concat([baseline_metrics, rf_metrics, lstm_metrics], axis=1)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
