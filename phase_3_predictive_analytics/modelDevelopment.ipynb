{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2530cd2a",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8351ef",
   "metadata": {},
   "source": [
    "### Prepping data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "eacc6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.75.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kanika/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.10.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow scikit-learn pandas matplotlib seaborn numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9b2ce5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "833be42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>825.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>716.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>67.2</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>956.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>909.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>615.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>66.6</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>996.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>648.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.7</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0  2004-01-04  0:00:00     1.6       1143.0     106.0       6.3   \n",
       "1  2004-01-04  2:00:00     1.1       1034.0      71.0       4.1   \n",
       "2  2004-01-04  3:00:00     0.9        956.0      72.0       4.0   \n",
       "3  2004-01-04  4:00:00     0.7        909.0      44.0       2.4   \n",
       "4  2004-01-04  5:00:00     0.9        996.0      45.0       2.9   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0          825.0     96.0         986.0     86.0        1477.0        978.0   \n",
       "1          716.0     50.0        1085.0     55.0        1405.0        891.0   \n",
       "2          713.0      NaN        1099.0      NaN        1422.0        849.0   \n",
       "3          615.0     57.0        1237.0     49.0        1322.0        790.0   \n",
       "4          648.0     64.0        1176.0     50.0        1340.0        852.0   \n",
       "\n",
       "      T    RH      AH year_month  \n",
       "0  12.0  61.6  0.8593    2004-01  \n",
       "1  10.7  67.2  0.8630    2004-01  \n",
       "2   9.0  73.1  0.8394    2004-01  \n",
       "3  10.2  66.6  0.8299    2004-01  \n",
       "4  11.0  63.7  0.8325    2004-01  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all the CSV files in the directory\n",
    "data_dir = '../data'\n",
    "all_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "df_list = [pd.read_csv(f) for f in all_files]\n",
    "data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Sort by datatimestamp\n",
    "data = data.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "509463c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                0\n",
       "Time                0\n",
       "CO(GT)            700\n",
       "PT08.S1(CO)       206\n",
       "NMHC(GT)         3538\n",
       "C6H6(GT)          206\n",
       "PT08.S2(NMHC)     206\n",
       "NOx(GT)           810\n",
       "PT08.S3(NOx)      206\n",
       "NO2(GT)           812\n",
       "PT08.S4(NO2)      206\n",
       "PT08.S5(O3)       206\n",
       "T                 206\n",
       "RH                206\n",
       "AH                206\n",
       "year_month          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba128bf2",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "655a9d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>825.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>716.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>67.2</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>956.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>909.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>615.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>66.6</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>996.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>648.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.7</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  \\\n",
       "0     1.6       1143.0     106.0       6.3          825.0     96.0   \n",
       "1     1.1       1034.0      71.0       4.1          716.0     50.0   \n",
       "2     0.9        956.0      72.0       4.0          713.0      NaN   \n",
       "3     0.7        909.0      44.0       2.4          615.0     57.0   \n",
       "4     0.9        996.0      45.0       2.9          648.0     64.0   \n",
       "\n",
       "   PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  Year  \\\n",
       "0         986.0     86.0        1477.0        978.0  12.0  61.6  0.8593  2004   \n",
       "1        1085.0     55.0        1405.0        891.0  10.7  67.2  0.8630  2004   \n",
       "2        1099.0      NaN        1422.0        849.0   9.0  73.1  0.8394  2004   \n",
       "3        1237.0     49.0        1322.0        790.0  10.2  66.6  0.8299  2004   \n",
       "4        1176.0     50.0        1340.0        852.0  11.0  63.7  0.8325  2004   \n",
       "\n",
       "   Month  Day  DayOfWeek  IsWeekend  Hour  \n",
       "0      1    4          6          1     0  \n",
       "1      1    4          6          1     2  \n",
       "2      1    4          6          1     3  \n",
       "3      1    4          6          1     4  \n",
       "4      1    4          6          1     5  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Date related columns from 'Date' column\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
    "data['IsWeekend'] = data['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Convert time column to datetime\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S')\n",
    "data['Hour'] = data['Time'].dt.hour\n",
    "\n",
    "data = data.drop(columns=['Time', 'year_month', 'Date'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "825f1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Season column\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "data['Season'] = data['Month'].apply(get_season)\n",
    "\n",
    "# One-hot encoding for Season\n",
    "data = pd.get_dummies(data, columns=['Season'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a0c103e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for Year\n",
    "data = pd.get_dummies(data, columns=['Year'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7565c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical Encoding for hour\n",
    "data['Hour_sin'] = np.sin(2 * np.pi * data['Hour'] / 24)\n",
    "data['Hour_cos'] = np.cos(2 * np.pi * data['Hour'] / 24)\n",
    "data = data.drop(columns=['Hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "294135c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycilical Encoding for Month\n",
    "data['Month_sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
    "data['Month_cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
    "data = data.drop(columns=['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c026d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "688f41dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)',\n",
       "       'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)',\n",
       "       'T', 'RH', 'AH', 'Day', 'DayOfWeek', 'IsWeekend', 'Season_spring',\n",
       "       'Season_summer', 'Season_winter', 'Year_2005', 'Hour_sin', 'Hour_cos',\n",
       "       'Month_sin', 'Month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff804e3",
   "metadata": {},
   "source": [
    "### Baseline Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "54252daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_71338/1916225933.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y = data[target].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT)</th>\n",
       "      <td>0.715873</td>\n",
       "      <td>1.249437</td>\n",
       "      <td>0.163001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <td>3.880327</td>\n",
       "      <td>36.774404</td>\n",
       "      <td>0.239170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <td>15.160911</td>\n",
       "      <td>4176.093140</td>\n",
       "      <td>0.272041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOx(GT)</th>\n",
       "      <td>79.901954</td>\n",
       "      <td>18134.807847</td>\n",
       "      <td>0.407981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2(GT)</th>\n",
       "      <td>21.901230</td>\n",
       "      <td>1090.107564</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MAE          RMSE        R2\n",
       "CO(GT)     0.715873      1.249437  0.163001\n",
       "C6H6(GT)   3.880327     36.774404  0.239170\n",
       "NMHC(GT)  15.160911   4176.093140  0.272041\n",
       "NOx(GT)   79.901954  18134.807847  0.407981\n",
       "NO2(GT)   21.901230   1090.107564  0.391304"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive pred using prev value\n",
    "targets = ['CO(GT)', 'C6H6(GT)', 'NMHC(GT)', 'NOx(GT)', 'NO2(GT)']  # add others as needed\n",
    "baseline_results = {}\n",
    "\n",
    "for target in targets:\n",
    "    y = data[target].fillna(method='ffill')  \n",
    "    y_pred = y.shift(1).iloc[1:]            \n",
    "    y_true = y.iloc[1:]\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    baseline_results[target] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "    \n",
    "baseline_results_df = pd.DataFrame(baseline_results).T\n",
    "baseline_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605fcd2",
   "metadata": {},
   "source": [
    "### Define Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6a63a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (CO)\n",
    "targetCO = data['CO(GT)']\n",
    "otherSensorsCO = ['PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresCO = data[['PT08.S1(CO)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsCO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3640d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NOx)\n",
    "targetNOx = data['NOx(GT)']\n",
    "otherSensorsNOx = ['PT08.S2(NMHC)', 'PT08.S1(CO)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresNOx = data[['PT08.S3(NOx)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNOx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f1e6c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NMHC)\n",
    "targetNMHC = data['NMHC(GT)']\n",
    "otherSensorsNMHC = ['PT08.S1(CO)', 'PT08.S3(NOx)', 'PT08.S4(NO2)', 'PT08.S5(O3)']\n",
    "featuresNMHC = data[['PT08.S2(NMHC)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNMHC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "50df5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (NO2)\n",
    "targetNO2 = data['NO2(GT)']\n",
    "otherSensorsNO2 = ['PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S5(O3)']\n",
    "featuresNO2 = data[['PT08.S4(NO2)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsNO2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e8bc357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable (C6H6)\n",
    "targetC6H6 = data['C6H6(GT)']\n",
    "otherSensorsC6H6 = ['PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)']\n",
    "featuresC6H6 = data[['PT08.S5(O3)', 'T', 'RH', 'AH', 'Year_2005', 'Day', 'DayOfWeek', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Season_spring', 'Season_summer'] + otherSensorsC6H6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40c3b6",
   "metadata": {},
   "source": [
    "### Random Forest for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "46e89030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.6567\n",
      "Random Forest R2: 0.6531\n",
      "Random Forest MAE: 0.5339\n"
     ]
    }
   ],
   "source": [
    "# Random forest for CO prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresCO) * 0.8)\n",
    "X_train, X_test = featuresCO.iloc[:split_idx], featuresCO.iloc[split_idx:]\n",
    "y_train, y_test = targetCO.iloc[:split_idx], targetCO.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predCO = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseCO = mean_squared_error(y_test, y_predCO)\n",
    "r2CO = r2_score(y_test, y_predCO)\n",
    "maeCO = np.mean(np.abs(y_test - y_predCO))\n",
    "\n",
    "print(f\"Random Forest MSE: {mseCO:.4f}\")\n",
    "print(f\"Random Forest R2: {r2CO:.4f}\")\n",
    "print(f\"Random Forest MAE: {maeCO:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d7afc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3300.000000\n",
      "mean        2.102068\n",
      "std         1.177624\n",
      "min         0.100000\n",
      "25%         1.300000\n",
      "50%         2.136398\n",
      "75%         2.500000\n",
      "max         9.400000\n",
      "Name: CO(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "70a81f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NOx MSE: 35739.4641\n",
      "Random Forest NOx R2: 0.2711\n",
      "Random Forest NOx MAE: 129.4883\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NOx prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresNOx) * 0.8)\n",
    "X_train, X_test = featuresNOx.iloc[:split_idx], featuresNOx.iloc[split_idx:]\n",
    "y_train, y_test = targetNOx.iloc[:split_idx], targetNOx.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNOx = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNOx = mean_squared_error(y_test, y_predNOx)\n",
    "r2NOx = r2_score(y_test, y_predNOx)\n",
    "maeNOx = np.mean(np.abs(y_test - y_predNOx))\n",
    "\n",
    "print(f\"Random Forest NOx MSE: {mseNOx:.4f}\")\n",
    "print(f\"Random Forest NOx R2: {r2NOx:.4f}\")\n",
    "print(f\"Random Forest NOx MAE: {maeNOx:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5e4251b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3300.000000\n",
      "mean      199.650957\n",
      "std       144.916482\n",
      "min         2.000000\n",
      "25%        95.000000\n",
      "50%       190.000000\n",
      "75%       231.379071\n",
      "max      1247.000000\n",
      "Name: NOx(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "61fe63ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NMHC MSE: 25550.3967\n",
      "Random Forest NMHC R2: -31629859089887759990535747534848.0000\n",
      "Random Forest NMHC MAE: 102.2592\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NMHC prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresNMHC) * 0.8)\n",
    "X_train, X_test = featuresNMHC.iloc[:split_idx], featuresNMHC.iloc[split_idx:]\n",
    "y_train, y_test = targetNMHC.iloc[:split_idx], targetNMHC.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNMHC = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNMHC = mean_squared_error(y_test, y_predNMHC)\n",
    "r2NMHC = r2_score(y_test, y_predNMHC)\n",
    "maeNMHC = np.mean(np.abs(y_test - y_predNMHC))\n",
    "\n",
    "print(f\"Random Forest NMHC MSE: {mseNMHC:.4f}\")\n",
    "print(f\"Random Forest NMHC R2: {r2NMHC:.4f}\")\n",
    "print(f\"Random Forest NMHC MAE: {maeNMHC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "24622433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3300.000000\n",
      "mean      205.751701\n",
      "std        84.711793\n",
      "min         7.000000\n",
      "25%       205.751701\n",
      "50%       205.751701\n",
      "75%       205.751701\n",
      "max      1084.000000\n",
      "Name: NMHC(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "40bc45e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest NO2 MSE: 2985.9885\n",
      "Random Forest NO2 R2: -0.1669\n",
      "Random Forest NO2 MAE: 40.9113\n"
     ]
    }
   ],
   "source": [
    "# Random forest for NO2 prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_index = int(0.8 * len(data))\n",
    "X_train, X_test = featuresNO2.iloc[:split_index], featuresNO2.iloc[split_index:]\n",
    "y_train, y_test = targetNO2.iloc[:split_index], targetNO2.iloc[split_index:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predNO2 = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseNO2 = mean_squared_error(y_test, y_predNO2)\n",
    "r2NO2 = r2_score(y_test, y_predNO2)\n",
    "maeNO2 = np.mean(np.abs(y_test - y_predNO2))\n",
    "\n",
    "print(f\"Random Forest NO2 MSE: {mseNO2:.4f}\")\n",
    "print(f\"Random Forest NO2 R2: {r2NO2:.4f}\")\n",
    "print(f\"Random Forest NO2 MAE: {maeNO2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "bdf93610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3300.000000\n",
      "mean       98.776701\n",
      "std        32.651140\n",
      "min         5.000000\n",
      "25%        76.000000\n",
      "50%       109.101690\n",
      "75%       112.000000\n",
      "max       233.000000\n",
      "Name: NO2(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d1114a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest C6H6 MSE: 0.0011\n",
      "Random Forest C6H6 R2: 1.0000\n",
      "Random Forest C6H6 MAE: 0.0145\n"
     ]
    }
   ],
   "source": [
    "# Random forest for C6H6 prediction\n",
    "# Split the data into train and test sets\n",
    "# Using a time-based split to respect temporal order\n",
    "split_idx = int(len(featuresC6H6) * 0.8)\n",
    "X_train, X_test = featuresC6H6.iloc[:split_idx], featuresC6H6.iloc[split_idx:]\n",
    "y_train, y_test = targetC6H6.iloc[:split_idx], targetC6H6.iloc[split_idx:]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predC6H6 = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mseC6H6 = mean_squared_error(y_test, y_predC6H6)\n",
    "r2C6H6 = r2_score(y_test, y_predC6H6)\n",
    "maeC6H6 = np.mean(np.abs(y_test - y_predC6H6))\n",
    "\n",
    "print(f\"Random Forest C6H6 MSE: {mseC6H6:.4f}\")\n",
    "print(f\"Random Forest C6H6 R2: {r2C6H6:.4f}\")\n",
    "print(f\"Random Forest C6H6 MAE: {maeC6H6:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ff384276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3300.000000\n",
      "mean       10.344737\n",
      "std         7.139922\n",
      "min         0.300000\n",
      "25%         5.100000\n",
      "50%         8.900000\n",
      "75%        13.700000\n",
      "max        48.200000\n",
      "Name: C6H6(GT), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c84efb",
   "metadata": {},
   "source": [
    "### LSTM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "507fb7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Year_2005</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Season_spring</th>\n",
       "      <th>Season_summer</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1143.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>825.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1034.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>67.2</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>713.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>909.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>66.6</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>615.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.7</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>648.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>972.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>542.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>992.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>73.1</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>565.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>1053.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>66.1</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>671.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>1140.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>800.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>1128.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>740.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>1064.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4126 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PT08.S1(CO)     T    RH      AH  Year_2005  Day  DayOfWeek  IsWeekend  \\\n",
       "0          1143.0  12.0  61.6  0.8593      False    4          6          1   \n",
       "1          1034.0  10.7  67.2  0.8630      False    4          6          1   \n",
       "2           956.0   9.0  73.1  0.8394      False    4          6          1   \n",
       "3           909.0  10.2  66.6  0.8299      False    4          6          1   \n",
       "4           996.0  11.0  63.7  0.8325      False    4          6          1   \n",
       "...           ...   ...   ...     ...        ...  ...        ...        ...   \n",
       "4121        972.0   9.2  75.3  0.8764       True    3          5          1   \n",
       "4122        992.0   9.4  73.1  0.8621       True    3          5          1   \n",
       "4123       1053.0  10.6  66.1  0.8444       True    3          5          1   \n",
       "4124       1140.0  12.6  58.5  0.8517       True    3          5          1   \n",
       "4125       1128.0  10.2  57.9  0.7191       True    3          5          1   \n",
       "\n",
       "      Hour_sin      Hour_cos     Month_sin  Month_cos  Season_spring  \\\n",
       "0     0.000000  1.000000e+00  5.000000e-01   0.866025          False   \n",
       "1     0.500000  8.660254e-01  5.000000e-01   0.866025          False   \n",
       "2     0.707107  7.071068e-01  5.000000e-01   0.866025          False   \n",
       "3     0.866025  5.000000e-01  5.000000e-01   0.866025          False   \n",
       "4     0.965926  2.588190e-01  5.000000e-01   0.866025          False   \n",
       "...        ...           ...           ...        ...            ...   \n",
       "4121  1.000000  6.123234e-17 -2.449294e-16   1.000000          False   \n",
       "4122  0.965926 -2.588190e-01 -2.449294e-16   1.000000          False   \n",
       "4123  0.866025 -5.000000e-01 -2.449294e-16   1.000000          False   \n",
       "4124  0.707107 -7.071068e-01 -2.449294e-16   1.000000          False   \n",
       "4125  0.707107  7.071068e-01 -2.449294e-16   1.000000          False   \n",
       "\n",
       "      Season_summer  PT08.S2(NMHC)  PT08.S3(NOx)  PT08.S4(NO2)  PT08.S5(O3)  \n",
       "0             False          825.0         986.0        1477.0        978.0  \n",
       "1             False          716.0        1085.0        1405.0        891.0  \n",
       "2             False          713.0        1099.0        1422.0        849.0  \n",
       "3             False          615.0        1237.0        1322.0        790.0  \n",
       "4             False          648.0        1176.0        1340.0        852.0  \n",
       "...             ...            ...           ...           ...          ...  \n",
       "4121          False          542.0        1029.0        1056.0        443.0  \n",
       "4122          False          565.0         912.0        1074.0        547.0  \n",
       "4123          False          671.0         807.0        1137.0        570.0  \n",
       "4124          False          800.0         679.0        1209.0        782.0  \n",
       "4125          False          740.0         705.0        1113.0       1064.0  \n",
       "\n",
       "[4126 rows x 18 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "121095db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 2/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 3/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 4/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 5/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 6/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 7/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 8/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 9/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 10/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 11/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 12/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 14/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 15/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 17/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 18/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 19/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 21/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 24/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 26/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 27/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 29/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 31/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 33/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 34/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0115\n",
      "Epoch 36/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0105\n",
      "Epoch 38/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0089 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 41/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0117\n",
      "Epoch 45/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0112\n",
      "Epoch 46/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0126\n",
      "Epoch 47/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0114\n",
      "Epoch 50/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0115\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "LSTM CO RMSE: 1.2996\n",
      "LSTM CO R2: 0.1092\n",
      "LSTM CO MAE: 1.0421\n"
     ]
    }
   ],
   "source": [
    "#LSTM pred for CO\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresCO.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetCO.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse scale to original CO values\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMCO = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMCO = r2_score(y_test_inv, y_pred_inv)\n",
    "# Calculate MAE\n",
    "maeLSTMCO = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM CO RMSE: {rmseLSTMCO:.4f}\")\n",
    "print(f\"LSTM CO R2: {r2LSTMCO:.4f}\")\n",
    "print(f\"LSTM CO MAE: {maeLSTMCO:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "77fa7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 2/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 5/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 6/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 7/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 8/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 9/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 10/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 11/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 12/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 13/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 14/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 15/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 16/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 17/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 18/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 19/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 20/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 21/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 24/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 25/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 26/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 28/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 29/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 30/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0078\n",
      "Epoch 32/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 33/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0084\n",
      "Epoch 34/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0086\n",
      "Epoch 38/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0092\n",
      "Epoch 39/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 41/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0086\n",
      "Epoch 42/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 50/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0086\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "LSTM NOx RMSE: 287.4973\n",
      "LSTM NOx R2: -0.6835\n",
      "LSTM NOx MAE: 210.7501\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NOx\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresNOx.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNOx.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split  =0.1)\n",
    "\n",
    "# Predict \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNOx = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMNOx = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNOx = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NOx RMSE: {rmseLSTMNOx:.4f}\")\n",
    "print(f\"LSTM NOx R2: {r2LSTMNOx:.4f}\")\n",
    "print(f\"LSTM NOx MAE: {maeLSTMNOx:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d5fa8a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 4/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0085\n",
      "Epoch 5/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 8/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 9/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 12/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 13/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 15/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0080\n",
      "Epoch 16/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 19/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0076\n",
      "Epoch 21/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 24/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0090\n",
      "Epoch 26/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0063\n",
      "Epoch 27/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 28/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 29/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0079\n",
      "Epoch 31/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0082\n",
      "Epoch 32/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 33/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0081\n",
      "Epoch 34/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 35/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0028 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0094\n",
      "Epoch 37/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0076\n",
      "Epoch 40/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 42/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0087\n",
      "Epoch 43/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0076\n",
      "Epoch 47/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0077\n",
      "Epoch 48/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 49/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0068\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "LSTM NMHC RMSE: 112.7192\n",
      "LSTM NMHC R2: -3932200015776862790843352743936.0000\n",
      "LSTM NMHC MAE: 81.6899\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NMHC\n",
    "\n",
    "# Features (all numeric columns)\n",
    "X = featuresNMHC.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNMHC.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNMHC = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMNMHC = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNMHC = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NMHC RMSE: {rmseLSTMNMHC:.4f}\")\n",
    "print(f\"LSTM NMHC R2: {r2LSTMNMHC:.4f}\")\n",
    "print(f\"LSTM NMHC MAE: {maeLSTMNMHC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c7202832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - val_loss: 0.0068\n",
      "Epoch 2/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 3/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 5/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 6/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 7/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 8/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 9/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 10/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 12/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 14/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 15/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 16/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 17/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 18/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 19/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 20/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 22/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 23/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 24/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 25/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 26/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 28/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 29/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 30/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 31/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 32/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 33/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0077\n",
      "Epoch 34/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 36/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 37/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 39/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 40/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 41/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 43/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0071\n",
      "Epoch 44/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 45/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 46/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0083\n",
      "Epoch 48/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0074\n",
      "Epoch 49/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Epoch 50/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0081\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "LSTM NO2 RMSE: 55.0443\n",
      "LSTM NO2 R2: -0.1813\n",
      "LSTM NO2 MAE: 40.4955\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for NO2\n",
    "# Features (all numeric columns)\n",
    "X = featuresNO2.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetNO2.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMNO2 = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMNO2 = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMNO2 = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM NO2 RMSE: {rmseLSTMNO2:.4f}\")\n",
    "print(f\"LSTM NO2 R2: {r2LSTMNO2:.4f}\")\n",
    "print(f\"LSTM NO2 MAE: {maeLSTMNO2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "be118b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 2/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0152 - val_loss: 0.0127\n",
      "Epoch 3/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 4/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 6/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 7/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0152\n",
      "Epoch 12/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 22/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 24/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 25/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 26/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 27/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 30/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 31/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 32/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0152\n",
      "Epoch 33/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 34/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0137\n",
      "Epoch 35/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 38/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0146\n",
      "Epoch 39/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 40/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0147\n",
      "Epoch 41/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0167\n",
      "Epoch 42/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 43/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0145\n",
      "Epoch 44/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0157\n",
      "Epoch 45/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0146\n",
      "Epoch 46/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0161\n",
      "Epoch 47/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0143\n",
      "Epoch 48/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0145\n",
      "Epoch 49/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0154\n",
      "Epoch 50/50\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0162\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "LSTM C6H6 RMSE: 7.2709\n",
      "LSTM C6H6 R2: -0.4372\n",
      "LSTM C6H6 MAE: 5.9332\n"
     ]
    }
   ],
   "source": [
    "# LSTM pred for C6H6\n",
    "# Features (all numeric columns)\n",
    "X = featuresC6H6.values  # shape: (num_samples, num_features)\n",
    "\n",
    "# Target\n",
    "y = targetC6H6.values.reshape(-1, 1)  # make it 2D for scaler\n",
    "\n",
    "# Scale features\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale target\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "seq_length = 10  # number of past timesteps to use\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, X_seq.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1) \n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmseLSTMC6H6 = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "# Calculate R²\n",
    "r2LSTMC6H6 = r2_score(y_test_inv, y_pred_inv)   \n",
    "# Calculate MAE\n",
    "maeLSTMC6H6 = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"LSTM C6H6 RMSE: {rmseLSTMC6H6:.4f}\")\n",
    "print(f\"LSTM C6H6 R2: {r2LSTMC6H6:.4f}\")\n",
    "print(f\"LSTM C6H6 MAE: {maeLSTMC6H6:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af9b56",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "01abfadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_RMSE</th>\n",
       "      <th>Baseline_R2</th>\n",
       "      <th>Baseline_MAE</th>\n",
       "      <th>RandomForest_RMSE</th>\n",
       "      <th>RandomForest_R2</th>\n",
       "      <th>RandomForest_MAE</th>\n",
       "      <th>LSTM_RMSE</th>\n",
       "      <th>LSTM_R2</th>\n",
       "      <th>LSTM_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT)</th>\n",
       "      <td>1.249437</td>\n",
       "      <td>0.163001</td>\n",
       "      <td>0.715873</td>\n",
       "      <td>0.810346</td>\n",
       "      <td>6.530707e-01</td>\n",
       "      <td>0.533871</td>\n",
       "      <td>1.299601</td>\n",
       "      <td>1.092395e-01</td>\n",
       "      <td>1.042072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <td>36.774404</td>\n",
       "      <td>0.239170</td>\n",
       "      <td>3.880327</td>\n",
       "      <td>0.032890</td>\n",
       "      <td>9.999706e-01</td>\n",
       "      <td>0.014473</td>\n",
       "      <td>7.270918</td>\n",
       "      <td>-4.371704e-01</td>\n",
       "      <td>5.933194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <td>4176.093140</td>\n",
       "      <td>0.272041</td>\n",
       "      <td>15.160911</td>\n",
       "      <td>159.844915</td>\n",
       "      <td>-3.162986e+31</td>\n",
       "      <td>102.259191</td>\n",
       "      <td>112.719224</td>\n",
       "      <td>-3.932200e+30</td>\n",
       "      <td>81.689935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOx(GT)</th>\n",
       "      <td>18134.807847</td>\n",
       "      <td>0.407981</td>\n",
       "      <td>79.901954</td>\n",
       "      <td>189.048840</td>\n",
       "      <td>2.710955e-01</td>\n",
       "      <td>129.488256</td>\n",
       "      <td>287.497348</td>\n",
       "      <td>-6.834827e-01</td>\n",
       "      <td>210.750107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2(GT)</th>\n",
       "      <td>1090.107564</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>21.901230</td>\n",
       "      <td>54.644199</td>\n",
       "      <td>-1.669251e-01</td>\n",
       "      <td>40.911344</td>\n",
       "      <td>55.044288</td>\n",
       "      <td>-1.813188e-01</td>\n",
       "      <td>40.495548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_RMSE  Baseline_R2  Baseline_MAE  RandomForest_RMSE  \\\n",
       "CO(GT)         1.249437     0.163001      0.715873           0.810346   \n",
       "C6H6(GT)      36.774404     0.239170      3.880327           0.032890   \n",
       "NMHC(GT)    4176.093140     0.272041     15.160911         159.844915   \n",
       "NOx(GT)    18134.807847     0.407981     79.901954         189.048840   \n",
       "NO2(GT)     1090.107564     0.391304     21.901230          54.644199   \n",
       "\n",
       "          RandomForest_R2  RandomForest_MAE   LSTM_RMSE       LSTM_R2  \\\n",
       "CO(GT)       6.530707e-01          0.533871    1.299601  1.092395e-01   \n",
       "C6H6(GT)     9.999706e-01          0.014473    7.270918 -4.371704e-01   \n",
       "NMHC(GT)    -3.162986e+31        102.259191  112.719224 -3.932200e+30   \n",
       "NOx(GT)      2.710955e-01        129.488256  287.497348 -6.834827e-01   \n",
       "NO2(GT)     -1.669251e-01         40.911344   55.044288 -1.813188e-01   \n",
       "\n",
       "            LSTM_MAE  \n",
       "CO(GT)      1.042072  \n",
       "C6H6(GT)    5.933194  \n",
       "NMHC(GT)   81.689935  \n",
       "NOx(GT)   210.750107  \n",
       "NO2(GT)    40.495548  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect metrics for each chemical and method\n",
    "\n",
    "# Baseline\n",
    "baseline_metrics = baseline_results_df[['RMSE', 'R2', 'MAE']].copy()\n",
    "baseline_metrics.columns = ['Baseline_RMSE', 'Baseline_R2', 'Baseline_MAE']\n",
    "\n",
    "# Random Forest\n",
    "rf_metrics = pd.DataFrame({\n",
    "    'RandomForest_RMSE': [\n",
    "        mseCO**0.5, mseC6H6**0.5, mseNMHC**0.5, mseNOx**0.5, mseNO2**0.5\n",
    "    ],\n",
    "    'RandomForest_R2': [\n",
    "        r2CO, r2C6H6, r2NMHC, r2NOx, r2NO2\n",
    "    ],\n",
    "    'RandomForest_MAE': [\n",
    "        maeCO, maeC6H6, maeNMHC, maeNOx, maeNO2\n",
    "    ]\n",
    "}, index=baseline_metrics.index)\n",
    "\n",
    "# LSTM\n",
    "lstm_metrics = pd.DataFrame({\n",
    "    'LSTM_RMSE': [\n",
    "        rmseLSTMCO, rmseLSTMC6H6, rmseLSTMNMHC, rmseLSTMNOx, rmseLSTMNO2\n",
    "    ],\n",
    "    'LSTM_R2': [\n",
    "        r2LSTMCO, r2LSTMC6H6, r2LSTMNMHC, r2LSTMNOx, r2LSTMNO2\n",
    "    ],\n",
    "    'LSTM_MAE': [\n",
    "        maeLSTMCO, maeLSTMC6H6, maeLSTMNMHC, maeLSTMNOx, maeLSTMNO2\n",
    "    ]\n",
    "}, index=baseline_metrics.index)\n",
    "\n",
    "# Combine all metrics\n",
    "results_df = pd.concat([baseline_metrics, rf_metrics, lstm_metrics], axis=1)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
